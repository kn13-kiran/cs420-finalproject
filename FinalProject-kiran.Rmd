---
title: 'Final Project'
author: "Kiranmayee Nimashakavi,..."
date: ''
output:
   
  bookdown::html_document2: 
    toc: true
    number_sections: yes
    fig_caption: yes
    urlcolor: cyan
    toc_depth: 4
---

\usepackage{subfig}
\DeclareUnicodeCharacter{00A0}{~}

***


```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(tinytex.verbose = TRUE)
```


```{r message=FALSE, include=FALSE}
library("gridExtra")
library("MASS")
library("faraway")
library("lmtest")
library("stringr")
library("cowplot")
library("gridGraphics")
library("dplyr")
library("statsr")
library("GGally")
library("ggplot2")
library("tibble")
library("readr")
library("Hmisc")
```

# Introduction

### Title of Project

The title of our project is "House Price Prediction" based on King County dataset.

### Source of dataset


### Statement of personal interest


### Description of the dataset
* id - Unique ID for each home sold
* date - Date of the home sale
* price - Price of each home sold
* bedrooms - Number of bedrooms
* bathrooms - Number of bathrooms, where .5 accounts for a room with a toilet but no shower
* sqft_living - Square footage of the apartments interior living space
* sqft_lot - Square footage of the land space
* floors - Number of floors
* waterfront - A dummy variable for whether the apartment was overlooking the waterfront or not
* view - An index from 0 to 4 of how good the view of the property was
* condition - An index from 1 to 5 on the condition of the apartment,
* grade - An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 have a high quality level of construction and design.
* sqft_above - The square footage of the interior housing space that is above ground level
* sqft_basement - The square footage of the interior housing space that is below ground level
* yr_built - The year the house was initially built
* yr_renovated - The year of the houseâ€™s last renovation
* zipcode - What zipcode area the house is in
* lat - Lattitude
* long - Longitude
* sqft_living15 - The square footage of interior housing living space for the nearest 15 neighbors
* sqft_lot15 - The square footage of the land lots of the nearest 15 neighbors

### What are the variables?



### Goal of this model

The goal of the model we are creating is to accurately predict the price of the houses.

### Dataset structure

We can see the structure of the dataset below

```{r}
housing_data <-read.csv("housing_data.csv",as.is = FALSE )



str(housing_data)
```

# Method

## Data Cleaning


### Investigations - Visually looking at data statistics {#id1}


Now we investigate the dataset to see what actions we need to take with the dataset before creating a model

```{r message=FALSE, warning=FALSE, echo=FALSE, include=FALSE}
Hmisc::html(Hmisc::describe(housing_data))
```

Since the output is very long, we use echo=FALSE, but as a sample, we show the output below for the first 5 rows

```{r message=FALSE, warning=FALSE}
Hmisc::html(Hmisc::describe(housing_data[,1:21]), where=c('cwd', 'tmp'))
```



### Data Cleanup based on data inspection

We have 21 predictors available on the dataset. Based on the above dataset analysis, we can draw the following conclusions.

**Observations**
* The dataset has 21613 entries.
* Missing values - None of the observations have any missing values for any predictors.
* Predictors where >90% of the values are same - We can notice that  'view' has ~90% of the observations has same value. This indicates that the majority of the houses doesn't have view.We can also notice that 96% of the observations for 'yr_renovated' has same values. Though only less observations have 'view' column populated, by intuition we think that view can have significant on property price.  

**Columns that can be removed**

* Remove Id column since it is not a predictor and is simply a running id

Based on the above analysis we remove the ones that we want to remove and store the column names for the ones with missing values in a vector to be used later if necessary

```{r}
columns_to_remove <- c("id",'yr_renovated')

columns_to_keep <- colnames(housing_data)[!(colnames(housing_data) %in% columns_to_remove)]

housing_data_clean_df <- subset(housing_data, select = as.vector(eval(columns_to_keep)))

#housing_data_clean_df = sample(housing_data_clean_df, 5000, replace = TRUE, prob = NULL)
#housing_data_clean_df
```



###  Correlated predictors

Now, we've to find the predictors that have high correlation. We can take the predictor paris that has > 75% correlation as high co-relation.

In order to identify correlation we first create a dataframe that has only numeric predictors

```{r}
clean_df_numeric_only <- housing_data_clean_df[,sapply(housing_data_clean_df, is.numeric)]
```

Now we identify the correlation in numeric predictors. We mark all correlations less than .75 as NA, so that we can easily identify highly correlated features

For brevity of the report, we only show the head of the correlation matrix, while we had looked at the entire matrix to come to our conclusions below

```{r}
cor_relation = cor(clean_df_numeric_only, use = "complete.obs")
cor_relation[abs(cor_relation) < 0.70] <- NA
cor_relation
#head(cor_relation)
```



### Data Cleanup based on correlation

Based on the above correlation matrix, we make the below observations

**Remove the following predictors**

* sqft_living has strong co-relation to bathrooms(0.75), grade(0.76), sqft_above(0.87),sqft_living15(0.75).
* sqft_living15 has strong co-relation to  grade(0.71) ,sqft_above(0.73), sqft_living(.75).
* sqft_lot has strong co-relation with sqft_lot15(0.71). 


**Key factor**

* sqft_living has a 0.70 correlation with price. Given that, we should make sure sqft_living is part of the model.



```{r}
columns_removed <- c("sqft_living15", "sqft_lot15", "sqft_above")

columns_to_keep <- colnames(housing_data_clean_df)[!(colnames(housing_data_clean_df) %in% columns_removed)]

housing_data_clean_df <- subset(housing_data_clean_df, select = as.vector(eval(columns_to_keep)))

ncol(housing_data_clean_df)
#housing_data_clean_df

```

We are left with 16 possible predictors compared to the 21 that we begin with.


### Clean data set summary

We know that step wont work with missing values. But based on our analysis, we don't have any mission values.So, we donot need to remove any observations.

We started with 21613 observations and 21 columns and after our initial cleanup we end up with 21613 observations and 21 columns


## Transformation identification



### Pairs plot

Now, before we begin modeling, we look at the pairs plots to see if any of the parameters are an obvious choice for transformations

For the purpose of being able to see the plots clearly, we do two things for the visual of the pair plot

1) We only look at numeric columns
2) We filter out the columns that have 35 or less discrete values, since they will probably not be candidates for transformations

We wont save this interim dataset. It is only created to be able to see the distribution across many predictors clearly

```{r}
predictor_unique_values = 35
clean_df_numeric_only <- housing_data_clean_df[,sapply(housing_data_clean_df, is.numeric)]
predictor_to_remove_for_plot <- c()
removal_counter=1
for(pred in colnames(clean_df_numeric_only)) {
  k <- length(unique(clean_df_numeric_only[,pred])<predictor_unique_values)
  #cat(sprintf("\"%s\" \"%f\"\n", pred,k))
  if(k<predictor_unique_values){
    predictor_to_remove_for_plot[removal_counter] <- pred
    removal_counter <- removal_counter+1
  }
}
# as zipcode needs to be used as a categorical variable.
predictor_to_remove_for_plot[removal_counter]<-"zipcode"
predictor_to_remove_for_plot

keep_for_plot <- colnames(clean_df_numeric_only)[!(colnames(clean_df_numeric_only) %in% predictor_to_remove_for_plot)]

housing_data_clean_df_for_plot <- subset(clean_df_numeric_only, select = as.vector(eval(keep_for_plot)))

```



```{r fig.height=30, fig.width=35, message=FALSE, warning=FALSE}


ncol(clean_df_numeric_only)
ggpairs( housing_data_clean_df_for_plot, ggplot2::aes(color=I("sea green")), title = "ggpairs plot to see correlation and distribution", lower = list(continuous = wrap("smooth")), axisLabels = "show", switch = "both")
```

We make the following observations from the plot

**Potential for transformations**
* price
* sqft_living
* sqft_lot
* sqft_basement
* yr_built
* lat
* long

```{r}

draw_plots <-function(model = fit_1, pcol = 'sea green', lcol = 'red', alpha = .05) {
    g1 <- ggplot(data = model, aes(sample=.resid)) + 
      stat_qq(color=I(pcol)) + stat_qq_line(color = I(lcol)) +
      ggtitle("Normal QQ Plot") +  theme_light() 
    
    g2 <- ggplot(data = model, aes(x = fitted(model), y = resid(model))) +
      geom_point(color=I(pcol)) + geom_hline(yintercept=0, color = I(lcol)) +
      xlab("Fitted") + ylab("Residuals") + ggtitle("Residuals vs Fitted Plot") + theme_light() 
    
    #grid.arrange(g1, g2, ncol=2,nrow=1)
     plot_grid(g1,g2,
          labels = 'AUTO',
          hjust = 0, vjust = 1)
}

diagnostics <- function(model = fit_1, pcol = 'dodgerblue', lcol = 'red', alpha = .05,  testit = TRUE){
  
  if(testit == TRUE){
    shapiro_Normalcy_test_result <- shapiro.test(resid(model))$"p.value"
    
    bptest_Const_Variance_test_result <-  bptest(model)$"p.value"[[1]]
    
    rmse <- round(sqrt(mean(resid(model) ^ 2)), 4)
    aic <- extractAIC(model)[2]
    num_predictors <- num_predictors_in_formula(formula(model))
    
    l1 <- list(num_predictors=num_predictors, shapiro_Normalcy_test_pvalue=shapiro_Normalcy_test_result, bptest_Const_Variance_test_pvalue=bptest_Const_Variance_test_result, RMSE=rmse, AdjustedR2=summary(model)$"adj.r.squared", AIC=aic)
    
    return(l1)
  }
}
```

```{r}
create_formula <- function(data_set, response, cols_to_remove="", cols_to_add=""){
  
  predictor_list <- colnames(housing_data_clean_df)
  
  predictor_list <- predictor_list[!(predictor_list %in% cols_to_remove)]
  n <- length(predictor_list)

  for(i in 1:length(cols_to_add)){
    n <- n+1
    predictor_list[n] <- cols_to_add[i]
  }
  
  frm1 <- paste(response, " ~ ", paste(predictor_list, collapse = ' + '))
}
```

```{r}
num_predictors_in_formula <- function(model_formula){

  return(length(strsplit(as.character(model_formula)[3], fixed = TRUE, split = "+")[[1]]))
}

```


In order to validate that transformations are necessary we will start with a simple additive model and look at its diagnostics plots

```{r fig.height=5, fig.width=15, message=FALSE, warning=FALSE}
m1 <- lm("price~.", data=housing_data_clean_df)

#diagnostics(m1)
#knitr::kable(data.frame(draw_plots(m1)))
draw_plots(m1)
```


Based on the diagnostics and the plots we see that some kind of transformation for the response is necessary.



### Boxcox lambda identifications for response and predictors {#id2}



#### Response transformation identification

In order to figure out the transformation for the response, we find the lambda for it

```{r}
boxcox(m1)

```
We know that the most common Box-Cox Transformations are

|$\lambda$|Transformed Data|
|---------|-----------------|
|-2|$y^{-2}$|
|-1|$y^{-1}$|
|-.5|$1 \over \sqrt y$|
|0|ln(y)|
|.5|$\sqrt y$|
|1|y|
|2|$y^2$|

since our $\lambda$ is close to 0 we will do log transformations

We redo the model and look at the diagnostics plots again


```{r fig.height=5, fig.width=15, message=FALSE, warning=FALSE}
m2 <- lm("log(price)~.", data=housing_data_clean_df)
draw_plots(m2)
```

We see that the plots and the diagnostics are a lot better, but there seems to be some scope for improvement. 


#### Predictors transformation identification

Let us now identify the lambda transformations for the other columns we identified and using those variables as response, fit the model, but keep log(SalePrice) in the predictor with others


```{r}
m3 <- lm("sqft_living~.-price+log(price)", data = housing_data_clean_df)
boxcox(m3,xlab = "lambda for sqft_living")
```

We should apply log transformation to sqft_living since $\lambda$ is close to 0.

```{r}
m3 <- lm("sqft_lot~.-price+log(price)", data = housing_data_clean_df)
boxcox(m3,xlab = "lambda for sqft_lot")
```

We should apply log transformation to sqft_lot since $\lambda$ is close to 0.

```{r}
m3 <- lm("yr_built~.-price+log(price)", data = housing_data_clean_df)
boxcox(m3,xlab = "lambda for yr_built")
```

We should apply y^2 transformation to sqft_basement since $\lambda$ is close to 2.

```{r}
m3 <- lm("lat~.-price+log(price)", data = housing_data_clean_df)
bc <- boxcox(m3,xlab = "lambda for lat", lambda = seq(-200,400))
```

We need to do proper analysis of other variables. 


## Model Identification



### Models - Simple, transformation, and using step {#id3}

Based on the above analysis we create the below models to start with

1) A simple additive model
2) A model with the above transformations but without the extreme transformations for YearBuilt and YearRemodAdd

```{r}
#train_df = sample(housing_data_clean_df, 5000, replace = TRUE, prob = NULL)
train_df=sample_n(housing_data_clean_df, 5000)
#train_df
```

Take a random 5000 sample to create the model.


```{r}
m_additive <- lm(price~., data = train_df)
head(train_df)
```

```{r}
frm <- create_formula(train_df, "log(price)", c("price", "sqft_lot", "sqft_living","zipcode"), c("log(sqft_lot)", "log(sqft_living)","as.factor(zipcode)"))
 
#bedrooms + bathrooms + floors + waterfront + view + condition + grade 
frm
m_transform_1 <- lm(formula = frm, data = train_df)
coef(m_transform_1)

```

Now we use step backwards with aic for the above to find better versions of these models that are smaller than them

```{r}
m_additive_step <- step(m_additive, trace = 0)
(frm <- formula(m_additive_step))
frm
```

```{r}
m_transform_1_step <- step(m_transform_1, trace = 0)
(frm <- formula(m_transform_1_step))
frm
```

We now compare the diagnostics of these models

```{r statcomp}
m_additive_result <- diagnostics(m_additive)
m_additive_step_result <- diagnostics(m_additive_step )

m_transform_1_result <- diagnostics(m_transform_1 )
m_transform_1_step_result <- diagnostics(m_transform_1_step)

df_result <- rbind(m_additive = m_additive_result, 
                   m_additive_step = m_additive_step_result, 
                   m_transform_1 = m_transform_1_result, 
                   m_transform_1_step = m_transform_1_step_result)

knitr::kable(df_result)
```

Looking at the above table, we can clearly see that the additive model isnt yielding a good model. The RMSE is extremely high. Hence we will discard this model for now.




#### Anova test {#id4}

In order to confirm that the model generated using step (m_transform_1_step) is a better model than the m_transform_1 model, we will do an anova test

```{r}
anova(m_transform_1, m_transform_1_step)
```

Based on the anova test, we see that the smaller model is sufficient hence we move ahead with m_transform_1_step



#### Model selection

As we concluded above, we will use m_transform_1_step model going forward. Below is the formula of the model selected.

```{r}
formula(m_transform_1_step)
```




### Individual parameter significance test for selected model {#id5}

Looking at the diagnostics, we can improve the model little better. We will now look at the individual significant of the parameters of this model to see if we can eliminate any predictors

```{r}
a <- coef(summary(m_transform_1_step))[,"Pr(>|t|)"] 
names(a)
```


The above are all the coefficients of the model. We will use them to compare to the below filtered list of p-values > 0.01

We will use alpha = 0.01 
We now identify the individual columns that have p-value of greater than 0.01 and remove them from the dataset to create another model

```{r}
names(a[a>.01])
```

We will select all non-categorical variables that have $pvalue>.01$. We will not remove the zipcodes to avoid overfitting.

Now we modify the formula of the model that is best so far, and remove the above identified predictors from it

```{r}
remove_cols3 <- c("yr_built")

f <- formula(m_transform_1_step)
predictor_list <- str_split(f, pattern = fixed(" + "))[[3]]
predictor_list <- predictor_list[!(predictor_list %in% remove_cols3)]

# replacing the \n that str_spit introduces after 500 characters
predictor_list <- str_replace(predictor_list, "\n    ", "")
# create the formula
(frm1 <- paste("log(price) ~ ", paste(predictor_list, collapse = ' + ')))

```

Now we use the above formula to create the model

```{r}
m_transform_1_step_year <- lm(frm1, data = train_df)
```



#### Anova test

We do an anova test between the two models to make sure we have not discarded significant predictors

```{r}
anova(m_transform_1_step_year, m_transform_1_step)
```

Based on the result of the anova test, we see that for our smaller model we fail to reject the Null Hypothesis, hence we move ahead with this model



#### Diagnostic comparison {#id6}

Now we will compare the diagnostics of the 2 models


```{r}
m_transform_1_step_result <- diagnostics(m_transform_1_step )
m_transform_1_step_year_result <- diagnostics(m_transform_1_step_year )
df_result <- rbind(m_transform_1_step=m_transform_1_step_result, m_transform_1_step_year=m_transform_1_step_year_result)

knitr::kable(df_result)

```

We see that our diagnostic statistics are about the same, with minor degradation of the diagnostics for the smaller model. 



#### Model selection

We've selected m_transform_1_step_year, as this is smaller and  better model



### Variance Inflation factor identification {#id7}

We look at variance inflation factors, and filter by only vifs that are >5

```{r}
faraway::vif(m_transform_1_step_year)[faraway::vif(m_transform_1_step_year)>5]
```




### Influential points identification and handling {#id8}

We will now look at high influence points and investigate them

```{r}
influentials <- which(cooks.distance(m_transform_1_step_year) > (4 / length(cooks.distance(m_transform_1_step_year))))
length(influentials)
```

As an experiment we try and remove the influentials and see what impact this has on the diagnostics

```{r}
train_df_no_inf <- train_df[-influentials,]
train_df_inf <- train_df[influentials,]

model_no_inf <- lm(formula(m_transform_1_step_year), data = train_df_no_inf)

```



#### Diagnostics Comparison

Now we compare the diagnostics data

```{r}

m_transform_1_step_year_result <- diagnostics(m_transform_1_step_year )
model_no_inf_result <- diagnostics(model_no_inf )

df_result <- rbind(m_transform_1_step_year = m_transform_1_step_year_result, 
                   model_no_inf = model_no_inf_result)

knitr::kable(df_result)
```



## Selected model


```{r}
#formula(model_no_inf)
```

## Predicting using the test data from the model and comparing efficiency

```{r}
test_df=sample_n(housing_data_clean_df, 5000)
table = data.frame(Model = c("Interaction"),
                   Train_RMSE = c(sqrt(mean((train_df_no_inf$price - predict(model_no_inf, train_df_no_inf)) ^ 2))),
                   Test_RMSE = c(sqrt(mean((test_df$price - predict(model_no_inf, test_df)) ^ 2)))
)
knitr::kable(table, caption = "RMSE")
```



# Results



## Comparison of all models



```{r}

df_result <- rbind(m_additive = m_additive_result,
                   m_additive_step = m_additive_step_result,
                   m_transform_1 = m_transform_1_result,
                   m_transform_1_step = m_transform_1_step_result,
                   m_transform_1_step_year = m_transform_1_step_year_result, 
                   model_no_inf = model_no_inf_result)

knitr::kable(df_result)
```



## Diagnostic plots of Selected Model

We also look at the diagnostics plot of our selected model

```{r fig.height=5, fig.width=15, message=FALSE, warning=FALSE}
draw_plots(model_no_inf)

```

 

# Discussion

After looking at the diagnostics plot we come to the final conclusion that we have a good enough model


```{r}
knitr::kable(data.frame(diagnostics(model_no_inf)))
```




## Names of the team members





