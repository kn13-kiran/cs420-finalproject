---
title: 'Final Project'
author: "Kiranmayee Nimashakavi,..."
date: ''
output:
   
  bookdown::html_document2: 
    toc: true
    number_sections: yes
    fig_caption: yes
    urlcolor: cyan
    toc_depth: 4
---

\usepackage{subfig}
\DeclareUnicodeCharacter{00A0}{~}

***


```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(tinytex.verbose = TRUE)
```


```{r message=FALSE, include=FALSE}
library("gridExtra")
library("MASS")
library("faraway")
library("lmtest")
library("stringr")
library("cowplot")
library("gridGraphics")
library("dplyr")
library("statsr")
library("GGally")
library("ggplot2")
library("tibble")
library("readr")
library("Hmisc")
```

# Introduction

### Title of Project

The title of our project is "House Price Prediction" based on King County dataset.

### Source of dataset


### Statement of personal interest


### Description of the dataset
* id - Unique ID for each home sold
* date - Date of the home sale
* price - Price of each home sold
* bedrooms - Number of bedrooms
* bathrooms - Number of bathrooms, where .5 accounts for a room with a toilet but no shower
* sqft_living - Square footage of the apartments interior living space
* sqft_lot - Square footage of the land space
* floors - Number of floors
* waterfront - A dummy variable for whether the apartment was overlooking the waterfront or not
* view - An index from 0 to 4 of how good the view of the property was
* condition - An index from 1 to 5 on the condition of the apartment,
* grade - An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 have a high quality level of construction and design.
* sqft_above - The square footage of the interior housing space that is above ground level
* sqft_basement - The square footage of the interior housing space that is below ground level
* yr_built - The year the house was initially built
* yr_renovated - The year of the houseâ€™s last renovation
* zipcode - What zipcode area the house is in
* lat - Lattitude
* long - Longitude
* sqft_living15 - The square footage of interior housing living space for the nearest 15 neighbors
* sqft_lot15 - The square footage of the land lots of the nearest 15 neighbors

### What are the variables?



### Goal of this model

The goal of the model we are creating is to accurately predict the price of the houses.

### Dataset structure

We can see the structure of the dataset below

```{r}
housing_data <-read.csv("kc_house_data.csv",as.is = FALSE )



str(housing_data)
```

# Method

## Data Cleaning


### Investigations - Visually looking at data statistics {#id1}


Now we investigate the dataset to see what actions we need to take with the dataset before creating a model

```{r message=FALSE, warning=FALSE, echo=FALSE, include=FALSE}
Hmisc::html(Hmisc::describe(housing_data))
```

Since the output is very long, we use echo=FALSE, but as a sample, we show the output below for the first 5 rows

```{r message=FALSE, warning=FALSE}
Hmisc::html(Hmisc::describe(housing_data[,1:21]), where=c('cwd', 'tmp'))
```



### Data Cleanup based on data inspection

We have 21 predictors available on the dataset. Based on the above dataset analysis, we can draw the following conclusions.

**Observations**
* The dataset has 21613 entries.
* Missing values - None of the observations have any missing values for any predictors.
* Predictors where >90% of the values are same - We can notice that  'view' has ~90% of the observations has same value. This indicates that the majority of the houses doesn't have view.We can also notice that 96% of the observations for 'yr_renovated' has same values. Though only less observations have 'view' column populated, by intuition we think that view can have significant on property price.  

**Columns that can be removed**

* Remove Id column since it is not a predictor and is simply a running id

Based on the above analysis we remove the ones that we want to remove and store the column names for the ones with missing values in a vector to be used later if necessary

```{r}
columns_to_remove <- c("id",'yr_renovated')

columns_to_keep <- colnames(housing_data)[!(colnames(housing_data) %in% columns_to_remove)]

housing_data_clean_df <- subset(housing_data, select = as.vector(eval(columns_to_keep)))

```



###  Correlated predictors

* Now, we've to find the predictors that have high correlation. We can take the predictor paris that has > 75% correlation as high co-relation.

* Create a dataframe that contains only numerics so that we can find co-relation.

```{r}
clean_df_numeric_only <- housing_data_clean_df[,sapply(housing_data_clean_df, is.numeric)]
```

* Now that we identified the correlation in numeric predictors, we canmark all correlations less than .70 as NA, so that we can easily identify highly correlated features.


```{r}
cor_relation = cor(clean_df_numeric_only, use = "complete.obs")
cor_relation[abs(cor_relation) < 0.70] <- NA
```



### Correlation Matrix - Data cleanup

Based on the above correlation matrix, we can make the below observations

**Predictors that can be removed**

* sqft_living has strong co-relation to bathrooms(0.75), grade(0.76), sqft_above(0.87),sqft_living15(0.75).
* sqft_living15 has strong co-relation to  grade(0.71) ,sqft_above(0.73), sqft_living(.75).
* sqft_lot has strong co-relation with sqft_lot15(0.71). 

**Key Observations**

* sqft_living has a 0.70 correlation with price. Given that, we should make sure sqft_living is part of the model.


```{r}
columns_removed <- c("sqft_living15", "sqft_lot15", "sqft_above")

columns_to_keep <- colnames(housing_data_clean_df)[!(colnames(housing_data_clean_df) %in% columns_removed)]

housing_data_clean_df <- subset(housing_data_clean_df, select = as.vector(eval(columns_to_keep)))

ncol(housing_data_clean_df)
#housing_data_clean_df

```

We are left with 16 possible predictors compared to the 21 that exist in the original dataset.


### Clean data set summary

* We know that step wont work with missing values. But based on our analysis, we don't have any mission values.So, we donot need to remove any observations.

* We started with 21613 observations and 21 columns and after our initial cleanup we end up with 21613 observations and 21 columns


## Transformation identification


### Pairs plot

Now, before we begin modeling, we look at the pairs plots to see if any of the parameters are an obvious choice for transformations

For the purpose of being able to see the plots clearly, we do two things for the visual of the pair plot

* Filter out the columns that have 35 or less discrete values, since they will probably not be candidates for transformations
* Focus only on numeric columns

```{r}
predictor_unique_values = 35
clean_df_numeric_only <- housing_data_clean_df[,sapply(housing_data_clean_df, is.numeric)]
predictor_to_remove_for_plot <- c()
removal_counter=1
for(pred in colnames(clean_df_numeric_only)) {
  k <- length(unique(clean_df_numeric_only[,pred])<predictor_unique_values)
  #cat(sprintf("\"%s\" \"%f\"\n", pred,k))
  if(k<predictor_unique_values){
    predictor_to_remove_for_plot[removal_counter] <- pred
    removal_counter <- removal_counter+1
  }
}
# as zipcode needs to be used as a categorical variable.
predictor_to_remove_for_plot[removal_counter]<-"zipcode"
predictor_to_remove_for_plot

plot_predictors <- colnames(clean_df_numeric_only)[!(colnames(clean_df_numeric_only) %in% predictor_to_remove_for_plot)]
housing_data_clean_df_for_plot <- subset(clean_df_numeric_only, select = as.vector(eval(plot_predictors)))

```



```{r fig.height=40, fig.width=40, message=FALSE, warning=FALSE}

ncol(clean_df_numeric_only)
ggpairs( housing_data_clean_df_for_plot, ggplot2::aes(color=I("sea green")), title = "ggpairs plot to see correlation and distribution", lower = list(continuous = wrap("smooth")), axisLabels = "show", switch = "both")
```

We make the following observations from the plot

**Potential for transformations**
* price
* sqft_living
* sqft_lot
* sqft_basement
* yr_built
* lat
* long

```{r}

# Helper function to draw plots
draw_plots <-function(model = fit_1, pcol = 'sea green', lcol = 'red', alpha = .05) {
    g1 <- ggplot(data = model, aes(sample=.resid)) + 
      stat_qq(color=I(pcol)) + stat_qq_line(color = I(lcol)) +
      ggtitle("Normal QQ Plot") +  theme_light() 
    
    g2 <- ggplot(data = model, aes(x = fitted(model), y = resid(model))) +
      geom_point(color=I(pcol)) + geom_hline(yintercept=0, color = I(lcol)) +
      xlab("Fitted") + ylab("Residuals") + ggtitle("Residuals vs Fitted Plot") + theme_light() 
    
     plot_grid(g1,g2,
          labels = 'AUTO',
          hjust = 0, vjust = 1)
}

# Helper function to calculate key statistics
key_statistics <- function(model = fit_1, alpha = .05){
  
    #shapiro_Normalcy_test_result <- shapiro.test(resid(model))$"p.value"
    # shapiro test cannot be performed datasize > 5000.
  
    shapiro_Normalcy_test_result =0
    predictors <- predictors_in_formula(formula(model))
    bptest_metric <-  bptest(model)$"p.value"[[1]]
    rmse <- round(sqrt(mean(resid(model) ^ 2)), 4)
    aic <- extractAIC(model)[2]
    
    key_stats <- list(predictors=predictors, shapiro_Normalcy_test_pvalue=shapiro_Normalcy_test_result, bptest_pval=bptest_metric, RMSE=rmse, AdjustedR2=summary(model)$"adj.r.squared", AIC=aic)
    return(key_stats)
}

# Helper function to build the formula.
build_formula <- function(data_set, response, columns_to_remove="", columns_to_add=""){
  predictor_list <- colnames(housing_data_clean_df)
  predictor_list <- predictor_list[!(predictor_list %in% columns_to_remove)]
  
  number_of_predictors <- length(predictor_list)

  for(i in 1:length(columns_to_add)){
    number_of_predictors <- number_of_predictors+1
    predictor_list[number_of_predictors] <- columns_to_add[i]
  }
  built_formula <- paste(response, " ~ ", paste(predictor_list, collapse = ' + '))
  built_formula
}

# Helper function to return the predictors in formula.

predictors_in_formula <- function(model_formula){
  return(length(strsplit(as.character(model_formula)[3], fixed = TRUE, split = "+")[[1]]))
}

```


* Create simple additive model and draw the plots.
```{r fig.height=5, fig.width=15, message=FALSE, warning=FALSE}
m1_add <- lm("price~.", data=housing_data_clean_df)
draw_plots(m1_add)
```


* Based on the statistics and the plots we see that some kind of transformation for the response is necessary.

### Boxcox lambda identifications for response and predictors {#id2}



#### Response transformation identification

In order to figure out the transformation for the response, we find the lambda for it

```{r}
boxcox(m1_add)

```
We know that the most common Box-Cox Transformations are

|$\lambda$|Transformed Data|
|---------|-----------------|
|-2|$y^{-2}$|
|-1|$y^{-1}$|
|-.5|$1 \over \sqrt y$|
|0|ln(y)|
|.5|$\sqrt y$|
|1|y|
|2|$y^2$|

since our $\lambda$ is close to 0 we will do log transformations

We redo the model and look at the diagnostics plots again

```{r fig.height=5, fig.width=15, message=FALSE, warning=FALSE}
m2 <- lm("log(price)~.", data=housing_data_clean_df)
draw_plots(m2)
```

We see that the plots and the statistics are a lot better, but there seems to be some scope for improvement. 

#### Identifyng the predictors that needs to be transformed

* We will identify the lambda transformations for the other columns we identified and using those variables as response, fit the model, but keep log(SalePrice) in the predictor with others

```{r}
m3 <- lm("sqft_living~.-price+log(price)", data = housing_data_clean_df)
boxcox(m3,xlab = "lambda for sqft_living")
```

We should apply log transformation to sqft_living since $\lambda$ is close to 0.

```{r}
m3 <- lm("sqft_lot~.-price+log(price)", data = housing_data_clean_df)
boxcox(m3,xlab = "lambda for sqft_lot")
```

We should apply log transformation to sqft_lot since $\lambda$ is close to 0.

```{r}
m3 <- lm("yr_built~.-price+log(price)", data = housing_data_clean_df)
boxcox(m3,xlab = "lambda for yr_built")
```

* We should apply y^2 transformation to sqft_basement since $\lambda$ is close to 2.

* To further optimize the model, we need to see any more additional variables can be removed.

## Model Creation & Selection


### Models - Simple, transformation, and using step {#id3}

Based on the above analysis we create the below models to start with

1) A simple additive model
2) A model with the above transformations but without the extreme transformations for YearBuilt and YearRemodAdd

* First we've to split the data, chose 80% of the test to be used as train and 20% for testing.
```{r}
kc_trn_idx  = sample(nrow(housing_data_clean_df), size = trunc(0.80 * nrow(housing_data_clean_df)))
train_df = housing_data_clean_df[kc_trn_idx, ]
test_df = housing_data_clean_df[-kc_trn_idx, ]
```

* Build addtive model.

```{r}
m_additive <- lm(price~., data = train_df)
head(train_df)
```

* Build an interactive model
* Use zipcode as a factor variable because zipcode should not be considered as numeric and it influences the house price significantly.

```{r}
interactive_formula <- build_formula(train_df, "log(price)", c("price", "sqft_lot", "sqft_living","zipcode"), c("log(sqft_lot)", "log(sqft_living)","as.factor(zipcode)"))
interactive_formula
m_transform_1 <- lm(formula = interactive_formula, data = train_df)
coef(m_transform_1)

```

Now we use step backwards with aic for the above to find better versions of these models that are smaller than them

```{r}
m_additive_step <- step(m_additive, trace = 0)
(additive_formula_step <- formula(m_additive_step))
additive_formula_step
```

```{r}
m_transform_1_step <- step(m_transform_1, trace = 0)
(interactive_formula_step <- formula(m_transform_1_step))
interactive_formula_step
```

We now compare the key statistics of these models

```{r statcomp}
m_additive_result <- key_statistics(m_additive)
m_additive_step_result <- key_statistics(m_additive_step )

m_transform_1_result <- key_statistics(m_transform_1 )
m_transform_1_step_result <- key_statistics(m_transform_1_step)

df_result <- rbind(m_additive = m_additive_result, 
                   m_additive_step = m_additive_step_result, 
                   m_transform_1 = m_transform_1_result, 
                   m_transform_1_step = m_transform_1_step_result)

knitr::kable(df_result)
```

Looking at the above table, we can clearly see that the additive model isnt yielding a good model. The RMSE is extremely high. Hence we will discard this model for now.


#### Anova test {#id4}

In order to confirm that the model generated using step (m_transform_1_step) is a better model than the m_transform_1 model, we will do an anova test

```{r}
anova(m_transform_1, m_transform_1_step)
```

Based on the anova test, we see that the smaller model is sufficient hence we move ahead with m_transform_1_step.

#### Model selection

As we concluded above, we will use m_transform_1_step model going forward. Below is the formula of the model selected.

```{r}
formula(m_transform_1_step)
```

### Checking the significance of individual parameters for selected model {#id5}

Looking at the diagnostics, we can improve the model little better. We will now look at the signficance of the parameters of this model to see if we can eliminate any predictors

```{r}
predictors <- coef(summary(m_transform_1_step))[,"Pr(>|t|)"] 
#names(predictors)
```

The above are all the coefficients of the model. We will use them to compare to the below filtered list of p-values > 0.01

We will use alpha = 0.01 
We now identify the individual columns that have p-value of greater than 0.01 and remove them from the dataset to create another model

```{r}
names(predictors[predictors>.01])
```

We will select all non-categorical variables that have $pvalue>.01$. We will not remove the zipcodes to avoid overfitting.
Now we modify the formula of the model that is best so far, and remove the above identified predictors from it

```{r}
remove_columns <- c("floors")

f <- formula(m_transform_1_step)
predictor_list <- str_split(f, pattern = fixed(" + "))[[3]]
predictor_list <- predictor_list[!(predictor_list %in% remove_columns)]

predictor_list <- str_replace(predictor_list, "\n    ", "")

# create the formula
(sig_formula <- paste("log(price) ~ ", paste(predictor_list, collapse = ' + ')))

```

Now we use the above formula to create the model

```{r}
m_transform_1_step_sig <- lm(sig_formula, data = train_df)
```


#### Anova test

We do an anova test between the two models to make sure we have not discarded significant predictors

```{r}
anova(m_transform_1_step_sig, m_transform_1_step)
```

Based on the result of the anova test, we can move ahead with m_transform_1_step_sig model as we can reduce one variable.

#### Diagnostic comparison {#id6}

Now we will compare the key stats of the 2 models


```{r}
m_transform_1_step_result <- key_statistics(m_transform_1_step )
m_transform_1_step_sig_result <- key_statistics(m_transform_1_step_sig )
df_result <- rbind(m_transform_1_step=m_transform_1_step_result, m_transform_1_step_sig=m_transform_1_step_sig_result)

knitr::kable(df_result)

```

#### Model selection

We've selected m_transform_1_step_sig, as this is smaller and  better model


### Variance Inflation factor identification {#id7}

We look at variance inflation factors, and filter by only vifs that are >5

```{r}
faraway::vif(m_transform_1_step_sig)[faraway::vif(m_transform_1_step_sig)>5]
```

### Influential points identification and handling {#id8}

We can check the high influence points and investigate them

```{r}
influentials <- which(cooks.distance(m_transform_1_step_sig) > (4 / length(cooks.distance(m_transform_1_step_sig))))
length(influentials)
```

As an experiment we try and remove the influentials and see what impact this has on the diagnostics

```{r}
train_df_no_inf <- train_df[-influentials,]
train_df_inf <- train_df[influentials,]

model_no_inf <- lm(formula(m_transform_1_step_sig), data = train_df_no_inf)
formula(model_no_inf)

```



#### Key Statistics Comparison

Now we compare the key statistics data

```{r}

m_transform_1_step_sig_result <- key_statistics(m_transform_1_step_sig )
model_no_inf_result <- key_statistics(model_no_inf )

df_result <- rbind(m_transform_1_step_sig = m_transform_1_step_sig_result, 
                   model_no_inf = model_no_inf_result)

knitr::kable(df_result)
```



## Selected model


```{r}
#formula(model_no_inf)
```

## Predicting using the test data from the model and comparing efficiency -- For some strange reason this is resulting in error.

```{r}
#test_df=sample_n(housing_data_clean_df, 5000)
#table = data.frame(Model = c("Interaction"),
#                   Train_RMSE = c(sqrt(mean((train_df_no_inf$price - predict(model_no_inf, train_df_no_inf)) ^ 2))),
#                   Test_RMSE = c(sqrt(mean((test_df$price - predict(model_no_inf, test_df)) ^ 2)))
#)
#knitr::kable(table, caption = "RMSE")
```

# Results



## Comparison of all models



```{r}

final_statistics <- rbind(m_additive = m_additive_result,
                   m_additive_step = m_additive_step_result,
                   m_transform_1 = m_transform_1_result,
                   m_transform_1_step = m_transform_1_step_result,
                   m_transform_1_step_sig = m_transform_1_step_sig_result, 
                   model_no_inf = model_no_inf_result)

knitr::kable(final_statistics)
```



##Plots for the Selected Model

We also look at the Q-Q/Fitted vs Residuals plot of our selected model

```{r fig.height=5, fig.width=15, message=FALSE, warning=FALSE}
draw_plots(model_no_inf)

```

 

# Discussion

After looking at the diagnostics plot we come to the final conclusion that we have a good enough model


```{r}
knitr::kable(data.frame(key_statistics(model_no_inf)))
```




## Names of the team members





